{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "import librosa\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (Input, Convolution2D, BatchNormalization, Flatten,\n",
    "                                     Dropout, Dense, AveragePooling2D, Add)\n",
    "from tensorflow.keras.callbacks import EarlyStopping,ModelCheckpoint\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! apt-get install libsndfile1 --y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! rm -r ./open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "# start = time.time()  # 시작 시간 저장\n",
    "\n",
    "# ! unzip ./open.zip -d ./open\n",
    "\n",
    "# print(\"time :\", time.time() - start)  # 현재시각 - 시작시간 = 실행 시간"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_paths = glob(\"./open/train_dataset/*\")\n",
    "test_data_paths = glob(\"./open/test_data/*\")\n",
    "train_label = pd.read_csv(\"./open/train_label.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./open/train_dataset/EB_0385-3028-04-01-PJW-M-05-A.wav',\n",
       " './open/train_dataset/EA_1520-1019-04-01-YJK-M-06-A.wav',\n",
       " './open/train_dataset/ED_1034-100-04-01-PEK-F-05-A.wav',\n",
       " './open/train_dataset/EB_0300-3014-04-01-LEH-F-06-A.wav',\n",
       " './open/train_dataset/EA_0507-1009-04-01-EJW-M-06-A.wav',\n",
       " './open/train_dataset/EB_0238-3025-04-01-KYJ-F-06-A.wav',\n",
       " './open/train_dataset/EA_0636-1517-04-01-CYJ-F-07-B.wav',\n",
       " './open/train_dataset/EB_0377-3031-04-01-KEJ-F-06-A.wav',\n",
       " './open/train_dataset/EA_0511-1011-04-01-KMS-F-05-A.wav',\n",
       " './open/train_dataset/EB_0260-3035-04-01-YSJ-M-06-A.wav']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_paths[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./open/test_data/938.wav',\n",
       " './open/test_data/1924.wav',\n",
       " './open/test_data/1703.wav',\n",
       " './open/test_data/1155.wav',\n",
       " './open/test_data/1757.wav',\n",
       " './open/test_data/218.wav',\n",
       " './open/test_data/916.wav',\n",
       " './open/test_data/1525.wav',\n",
       " './open/test_data/1758.wav',\n",
       " './open/test_data/671.wav']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_paths[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>age_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EA_0370-1000-04-01-LOH-F-08-A</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EA_0370-501-04-01-LOH-F-08-A</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EA_0370-502-04-01-LOH-F-08-A</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EA_0370-503-04-01-LOH-F-08-A</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EA_0370-504-04-01-LOH-F-08-A</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       file_name  age_\n",
       "0  EA_0370-1000-04-01-LOH-F-08-A     6\n",
       "1   EA_0370-501-04-01-LOH-F-08-A     6\n",
       "2   EA_0370-502-04-01-LOH-F-08-A     6\n",
       "3   EA_0370-503-04-01-LOH-F-08-A     6\n",
       "4   EA_0370-504-04-01-LOH-F-08-A     6"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    6368\n",
       "4    5855\n",
       "5    4534\n",
       "6    4436\n",
       "2    4026\n",
       "7      31\n",
       "1      31\n",
       "Name: age_, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label['age_'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(paths):\n",
    "\n",
    "    result = []\n",
    "    for path in tqdm(paths):\n",
    "        data, sr = librosa.load(path, sr = 16000)\n",
    "        result.append(data)\n",
    "    result = np.array(result) \n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data_ = load_data(train_data_paths)\n",
    "# np.save(\"./train_data_\", train_data_)\n",
    "\n",
    "# test_data_ = load_data(test_data_paths)\n",
    "# np.save(\"./test_data_\", test_data_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_ = np.load(\"./train_data_.npy\", allow_pickle = True)\n",
    "test_data_ = np.load(\"./test_data_.npy\", allow_pickle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max(data):\n",
    "    \n",
    "    max_ = 0\n",
    "    for i in data:\n",
    "        if len(i) > max_:\n",
    "            max_ = len(i)\n",
    "            \n",
    "    return max_\n",
    "\n",
    "def get_mini(data):\n",
    "\n",
    "    mini = 9999999\n",
    "    for i in data:\n",
    "        if len(i) < mini:\n",
    "            mini = len(i)\n",
    "\n",
    "    return mini\n",
    "\n",
    "def set_max_length(data, d_max):\n",
    "    result = []\n",
    "    for i in data:\n",
    "        tmp = np.zeros(d_max)\n",
    "        if d_max < len(i):\n",
    "            tmp = i[:d_max]\n",
    "        if d_max >= len(i):\n",
    "            tmp[:len(i)] = i\n",
    "        result.append(tmp)\n",
    "    result = np.array(result)\n",
    "    return result\n",
    "\n",
    "def set_length(data, d_mini):\n",
    "\n",
    "    result = []\n",
    "    for i in data:\n",
    "        result.append(i[:d_mini])\n",
    "    result = np.array(result)\n",
    "\n",
    "    return result\n",
    "\n",
    "def get_feature(data, sr = 16000,  n_fft = 256, win_length = 200, hop_length = 160, n_mels = 128):\n",
    "    mel = []\n",
    "    for i in tqdm(data):\n",
    "        mel_ = librosa.feature.melspectrogram(i, sr = sr, n_fft = n_fft, win_length = win_length, hop_length = hop_length, n_mels = n_mels)\n",
    "        mel.append(mel_)\n",
    "    mel = np.array(mel)\n",
    "    mel = librosa.power_to_db(mel, ref = np.max)\n",
    "\n",
    "    mel_mean = mel.mean()\n",
    "    mel_std = mel.std()\n",
    "    mel = (mel - mel_mean) / mel_std\n",
    "\n",
    "    return mel\n",
    "\n",
    "def gen_4_mels(data):\n",
    "    alpha = get_feature(data, n_fft=256, win_length=150, hop_length=160, n_mels=64) # 10 epochs, 1.09398\n",
    "    data = np.stack([alpha], axis=-1)\n",
    "    return data\n",
    "\n",
    "# def get_feature_mm(data, sr = 16000, n_fft = 2048, win_length = 512, hop_length = 160, n_mels = 128):\n",
    "#     mel = []\n",
    "#     for i in tqdm(data):\n",
    "#         mel_ = librosa.feature.melspectrogram(i, sr = sr, n_fft = n_fft, win_length = win_length, hop_length = hop_length, n_mels = n_mels)\n",
    "#         mel.append(mel_)\n",
    "#     mel = np.array(mel)\n",
    "#     mel = librosa.power_to_db(mel, ref = np.max)\n",
    "\n",
    "#     mel_min = mel.min()\n",
    "#     mel_max = mel.max()\n",
    "#     mel = (mel - mel_min) / (mel_max-mel_min)\n",
    "\n",
    "#     return mel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = np.array(train_data_)\n",
    "test_x = np.array(test_data_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25281,), (1990,))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape, test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 음성의 길이 중 가장 작은 길이를 구합니다.\n",
    "train_mini = get_mini(train_x)\n",
    "test_mini = get_mini(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training set: (25281,)\n",
      "train_min: 1920\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 데이터 길이 분포 확인\n",
    "print('total training set:', train_x.shape)\n",
    "print('train_min:', train_mini)\n",
    "data_len_list = []\n",
    "for i in train_x:\n",
    "    data_len_list.append(len(i))\n",
    "\n",
    "sns.rugplot(data_len_list)\n",
    "plt.title(\"Voice time length\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_train = []\n",
    "process_train_y = []\n",
    "for i in range(len(train_x)):\n",
    "    if len(train_x[i]) > 16000 and len(train_x[i]) < 200000:\n",
    "        process_train.append(train_x[i])\n",
    "        process_train_y.append(train_label[\"age_\"][i])\n",
    "        \n",
    "train_x = np.array(process_train)\n",
    "train_y = np.array(process_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25273,), (1990,), (25273,))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape, test_x.shape, train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 음성의 길이 중 가장 작은 길이를 구합니다.\n",
    "train_mini = get_mini(train_x)\n",
    "test_mini = get_mini(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training set: (25273,)\n",
      "train_min: 17280\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 데이터 길이 분포 확인\n",
    "print('total training set:', train_x.shape)\n",
    "print('train_min:', train_mini)\n",
    "data_len_list = []\n",
    "for i in train_x:\n",
    "    data_len_list.append(len(i))\n",
    "\n",
    "sns.rugplot(data_len_list)\n",
    "plt.title(\"Voice time length\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "mini = np.min([train_mini, test_mini])\n",
    "\n",
    "train_x = set_length(train_x, mini)\n",
    "test_x = set_length(test_x, mini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
       "        -2.3750310e-04, -2.7187628e-04, -4.2706315e-04],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
       "        -1.3086757e-04, -1.4231540e-04, -1.2343311e-04],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
       "        -4.9192440e-03,  8.3049182e-03,  5.2764989e-03],\n",
       "       ...,\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
       "        -6.0129777e-04,  5.0597754e-04,  1.7142133e-03],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
       "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
       "         3.0792236e-01,  3.8867188e-01,  3.9355469e-01]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_m = get_feature_mm(data = train_x)\n",
    "# test_m = get_feature_mm(data = test_x)\n",
    "\n",
    "# train_m = train_m.reshape(-1, train_m.shape[1], train_m.shape[2], 1)\n",
    "# test_m = test_m.reshape(-1, test_m.shape[1], test_m.shape[2], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25273/25273 [01:29<00:00, 282.01it/s]\n",
      "100%|██████████| 1990/1990 [00:04<00:00, 444.25it/s]\n"
     ]
    }
   ],
   "source": [
    "# librosa를 이용해 feature를 추출합니다.\n",
    "train_s = gen_4_mels(data=train_x)\n",
    "test_s = gen_4_mels(data=test_x)\n",
    "\n",
    "train_s = train_s.reshape(-1, train_s.shape[1], train_s.shape[2], 1)\n",
    "test_s = test_s.reshape(-1, test_s.shape[1], test_s.shape[2], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('./train_m.npy',arr=train_m)\n",
    "# np.save('./test_m.npy',arr=test_m)\n",
    "\n",
    "np.save('./train_s.npy',arr=train_s)\n",
    "np.save('./test_s.npy',arr=test_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25273,), (25273, 64, 97, 1), (1990, 64, 97, 1))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.shape, train_s.shape, test_s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.utils import to_categorical\n",
    "# train_y = to_categorical(train_y)\n",
    "# # y_val = to_categorical(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del train_m\n",
    "# del test_m\n",
    "del train_s\n",
    "del test_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n",
      "Number of devices: 2\n"
     ]
    }
   ],
   "source": [
    "# Create a MirroredStrategy.\n",
    "strategy = tf.distribute.MirroredStrategy(cross_device_ops=tf.distribute.ReductionToOneDevice())\n",
    "print(\"Number of devices: {}\".format(strategy.num_replicas_in_sync))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def block(input_, units = 32, dropout_rate = 0.5):\n",
    "    \n",
    "    x = Convolution2D(units, 3, padding =\"same\", activation = \"relu\")(input_)\n",
    "    x = BatchNormalization()(x)\n",
    "    x_res = x\n",
    "    x = Convolution2D(units, 3, padding =\"same\", activation = \"relu\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Convolution2D(units, 3, padding =\"same\", activation = \"relu\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Add()([x, x_res])\n",
    "    x = AveragePooling2D()(x)\n",
    "    x = Dropout(rate=dropout_rate)(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "def second_block(input_, units = 64, dropout_rate = 0.5):\n",
    "    \n",
    "    x = Convolution2D(units, 1, padding =\"same\", activation = \"relu\")(input_)\n",
    "    x = Convolution2D(units, 3, padding =\"same\", activation = \"relu\")(x)\n",
    "    x = Convolution2D(units * 4, 1, padding =\"same\", activation = \"relu\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x_res = x\n",
    "    x = Convolution2D(units, 1, padding =\"same\", activation = \"relu\")(x)\n",
    "    x = Convolution2D(units, 3, padding =\"same\", activation = \"relu\")(x)\n",
    "    x = Convolution2D(units * 4, 1, padding =\"same\", activation = \"relu\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Convolution2D(units, 1, padding = \"same\", activation = \"relu\")(x)\n",
    "    x = Convolution2D(units, 3, padding =\"same\", activation = \"relu\")(x)\n",
    "    x = Convolution2D(units * 4, 1, padding = \"same\", activation = \"relu\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Add()([x, x_res])\n",
    "    x = AveragePooling2D()(x)\n",
    "    x = Dropout(rate=dropout_rate)(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "def build_fn():\n",
    "    dropout_rate = 0.3\n",
    "    \n",
    "    in_ = Input(shape = (train_x.shape[1:]))\n",
    "    \n",
    "    block_01 = block(in_, units = 32, dropout_rate = dropout_rate)\n",
    "    block_02 = block(block_01, units = 64, dropout_rate = dropout_rate)\n",
    "    block_03 = block(block_02, units = 128, dropout_rate = dropout_rate)\n",
    "\n",
    "    block_04 = second_block(block_03, units = 64, dropout_rate = dropout_rate)\n",
    "    block_05 = second_block(block_04, units = 128, dropout_rate = dropout_rate)\n",
    "\n",
    "    x = Flatten()(block_05)\n",
    "\n",
    "    x = Dense(units = 128, activation = \"relu\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x_res = x\n",
    "    x = Dropout(rate = dropout_rate)(x)\n",
    "\n",
    "    x = Dense(units = 128, activation = \"relu\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Add()([x_res, x])\n",
    "    x = Dropout(rate = dropout_rate)(x)\n",
    "\n",
    "    model_out = Dense(units = 8, activation = 'softmax')(x)\n",
    "    model = Model(in_, model_out)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x= np.load('./train_s.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "Epoch 1/30\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1').\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1').\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1').\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1').\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1').\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1').\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1').\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1').\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1').\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1').\n",
      "711/711 [==============================] - 43s 39ms/step - loss: 2.2768 - accuracy: 0.1967 - val_loss: 1.6739 - val_accuracy: 0.2445\n",
      "Epoch 2/30\n",
      "711/711 [==============================] - 26s 36ms/step - loss: 1.7658 - accuracy: 0.2216 - val_loss: 1.7904 - val_accuracy: 0.2492\n",
      "Epoch 3/30\n",
      "711/711 [==============================] - 26s 36ms/step - loss: 1.6778 - accuracy: 0.2226 - val_loss: 1.6152 - val_accuracy: 0.2409\n",
      "Epoch 4/30\n",
      "711/711 [==============================] - 25s 36ms/step - loss: 1.6410 - accuracy: 0.2311 - val_loss: 1.6143 - val_accuracy: 0.2377\n",
      "Epoch 5/30\n",
      "711/711 [==============================] - 25s 35ms/step - loss: 1.6299 - accuracy: 0.2364 - val_loss: 1.6125 - val_accuracy: 0.2488\n",
      "Epoch 6/30\n",
      "711/711 [==============================] - 25s 35ms/step - loss: 1.6216 - accuracy: 0.2400 - val_loss: 1.6129 - val_accuracy: 0.2429\n",
      "Epoch 7/30\n",
      "711/711 [==============================] - 25s 35ms/step - loss: 1.6192 - accuracy: 0.2400 - val_loss: 1.6101 - val_accuracy: 0.2393\n",
      "Epoch 8/30\n",
      "711/711 [==============================] - 25s 35ms/step - loss: 1.6170 - accuracy: 0.2440 - val_loss: 1.6120 - val_accuracy: 0.2520\n",
      "Epoch 9/30\n",
      "711/711 [==============================] - 25s 35ms/step - loss: 1.6172 - accuracy: 0.2447 - val_loss: 1.6126 - val_accuracy: 0.2425\n",
      "Epoch 10/30\n",
      "711/711 [==============================] - 25s 35ms/step - loss: 1.6147 - accuracy: 0.2485 - val_loss: 1.6148 - val_accuracy: 0.2393\n",
      "*******************************************************************\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "Epoch 1/30\n",
      "711/711 [==============================] - 40s 38ms/step - loss: 2.2576 - accuracy: 0.1962 - val_loss: 1.6710 - val_accuracy: 0.2389\n",
      "Epoch 2/30\n",
      "711/711 [==============================] - 25s 35ms/step - loss: 1.7796 - accuracy: 0.2177 - val_loss: 1.6249 - val_accuracy: 0.2488\n",
      "Epoch 3/30\n",
      "711/711 [==============================] - 24s 34ms/step - loss: 1.6807 - accuracy: 0.2215 - val_loss: 1.6175 - val_accuracy: 0.2460\n",
      "Epoch 4/30\n",
      "711/711 [==============================] - 24s 34ms/step - loss: 1.6394 - accuracy: 0.2312 - val_loss: 1.6215 - val_accuracy: 0.2223\n",
      "Epoch 5/30\n",
      "711/711 [==============================] - 25s 35ms/step - loss: 1.6283 - accuracy: 0.2350 - val_loss: 1.6102 - val_accuracy: 0.2520\n",
      "Epoch 6/30\n",
      "711/711 [==============================] - 25s 35ms/step - loss: 1.6201 - accuracy: 0.2423 - val_loss: 1.6155 - val_accuracy: 0.2453\n",
      "Epoch 7/30\n",
      "711/711 [==============================] - 25s 35ms/step - loss: 1.6191 - accuracy: 0.2419 - val_loss: 1.6192 - val_accuracy: 0.2445\n",
      "Epoch 8/30\n",
      "711/711 [==============================] - 25s 35ms/step - loss: 1.6170 - accuracy: 0.2417 - val_loss: 1.6131 - val_accuracy: 0.2540\n",
      "*******************************************************************\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "Epoch 1/30\n",
      "711/711 [==============================] - 40s 38ms/step - loss: 2.2952 - accuracy: 0.1953 - val_loss: 1.6700 - val_accuracy: 0.2354\n",
      "Epoch 2/30\n",
      "711/711 [==============================] - 25s 35ms/step - loss: 1.7800 - accuracy: 0.2201 - val_loss: 1.7633 - val_accuracy: 0.2476\n",
      "Epoch 3/30\n",
      "711/711 [==============================] - 25s 35ms/step - loss: 1.6828 - accuracy: 0.2258 - val_loss: 1.6185 - val_accuracy: 0.2326\n",
      "Epoch 4/30\n",
      "711/711 [==============================] - 25s 35ms/step - loss: 1.6482 - accuracy: 0.2280 - val_loss: 1.6136 - val_accuracy: 0.2476\n",
      "Epoch 5/30\n",
      "711/711 [==============================] - 25s 35ms/step - loss: 1.6288 - accuracy: 0.2352 - val_loss: 1.6120 - val_accuracy: 0.2547\n",
      "Epoch 6/30\n",
      "711/711 [==============================] - 25s 35ms/step - loss: 1.6217 - accuracy: 0.2372 - val_loss: 1.6153 - val_accuracy: 0.2468\n",
      "Epoch 7/30\n",
      "711/711 [==============================] - 25s 35ms/step - loss: 1.6184 - accuracy: 0.2419 - val_loss: 1.6250 - val_accuracy: 0.2429\n",
      "Epoch 8/30\n",
      "711/711 [==============================] - 25s 35ms/step - loss: 1.6173 - accuracy: 0.2440 - val_loss: 1.6158 - val_accuracy: 0.2437\n",
      "*******************************************************************\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "Epoch 1/30\n",
      "711/711 [==============================] - 40s 38ms/step - loss: 2.1938 - accuracy: 0.1959 - val_loss: 1.6513 - val_accuracy: 0.2533\n",
      "Epoch 2/30\n",
      "711/711 [==============================] - 25s 35ms/step - loss: 1.7448 - accuracy: 0.2202 - val_loss: 1.6168 - val_accuracy: 0.2454\n",
      "Epoch 3/30\n",
      "711/711 [==============================] - 25s 35ms/step - loss: 1.6680 - accuracy: 0.2268 - val_loss: 1.6236 - val_accuracy: 0.2319\n",
      "Epoch 4/30\n",
      "711/711 [==============================] - 25s 36ms/step - loss: 1.6398 - accuracy: 0.2311 - val_loss: 1.6160 - val_accuracy: 0.2477\n",
      "Epoch 5/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "711/711 [==============================] - 25s 36ms/step - loss: 1.6266 - accuracy: 0.2373 - val_loss: 1.6193 - val_accuracy: 0.2513\n",
      "Epoch 6/30\n",
      "711/711 [==============================] - 25s 35ms/step - loss: 1.6181 - accuracy: 0.2418 - val_loss: 1.6155 - val_accuracy: 0.2335\n",
      "Epoch 7/30\n",
      "711/711 [==============================] - 25s 35ms/step - loss: 1.6174 - accuracy: 0.2436 - val_loss: 1.6117 - val_accuracy: 0.2418\n",
      "Epoch 8/30\n",
      "711/711 [==============================] - 25s 35ms/step - loss: 1.6162 - accuracy: 0.2433 - val_loss: 1.6120 - val_accuracy: 0.2434\n",
      "Epoch 9/30\n",
      "711/711 [==============================] - 25s 35ms/step - loss: 1.6165 - accuracy: 0.2429 - val_loss: 1.6408 - val_accuracy: 0.2493\n",
      "Epoch 10/30\n",
      "711/711 [==============================] - 25s 35ms/step - loss: 1.6169 - accuracy: 0.2421 - val_loss: 1.6099 - val_accuracy: 0.2505\n",
      "Epoch 11/30\n",
      "711/711 [==============================] - 25s 35ms/step - loss: 1.6141 - accuracy: 0.2438 - val_loss: 1.6167 - val_accuracy: 0.2430\n",
      "Epoch 12/30\n",
      "711/711 [==============================] - 25s 36ms/step - loss: 1.6140 - accuracy: 0.2466 - val_loss: 1.6107 - val_accuracy: 0.2517\n",
      "Epoch 13/30\n",
      "711/711 [==============================] - 25s 35ms/step - loss: 1.6133 - accuracy: 0.2455 - val_loss: 1.6143 - val_accuracy: 0.2501\n",
      "*******************************************************************\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "Epoch 1/30\n",
      "711/711 [==============================] - 41s 39ms/step - loss: 2.2125 - accuracy: 0.1981 - val_loss: 1.6854 - val_accuracy: 0.2129\n",
      "Epoch 2/30\n",
      "711/711 [==============================] - 25s 35ms/step - loss: 1.7502 - accuracy: 0.2134 - val_loss: 1.6204 - val_accuracy: 0.2390\n",
      "Epoch 3/30\n",
      "711/711 [==============================] - 25s 35ms/step - loss: 1.6639 - accuracy: 0.2231 - val_loss: 1.6142 - val_accuracy: 0.2509\n",
      "Epoch 4/30\n",
      "711/711 [==============================] - 25s 35ms/step - loss: 1.6345 - accuracy: 0.2347 - val_loss: 1.6091 - val_accuracy: 0.2505\n",
      "Epoch 5/30\n",
      "711/711 [==============================] - 25s 35ms/step - loss: 1.6233 - accuracy: 0.2393 - val_loss: 1.6102 - val_accuracy: 0.2517\n",
      "Epoch 6/30\n",
      "711/711 [==============================] - 25s 35ms/step - loss: 1.6200 - accuracy: 0.2426 - val_loss: 1.6188 - val_accuracy: 0.2465\n",
      "Epoch 7/30\n",
      "711/711 [==============================] - 26s 36ms/step - loss: 1.6185 - accuracy: 0.2400 - val_loss: 1.6143 - val_accuracy: 0.2505\n",
      "*******************************************************************\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 6 ...\n",
      "Epoch 1/30\n",
      "711/711 [==============================] - 41s 39ms/step - loss: 2.1669 - accuracy: 0.1968 - val_loss: 1.6422 - val_accuracy: 0.2244\n",
      "Epoch 2/30\n",
      "711/711 [==============================] - 25s 35ms/step - loss: 1.7269 - accuracy: 0.2172 - val_loss: 1.6257 - val_accuracy: 0.2382\n",
      "Epoch 3/30\n",
      "711/711 [==============================] - 25s 35ms/step - loss: 1.6614 - accuracy: 0.2216 - val_loss: 1.6161 - val_accuracy: 0.2355\n",
      "Epoch 4/30\n",
      "711/711 [==============================] - 25s 34ms/step - loss: 1.6330 - accuracy: 0.2329 - val_loss: 1.6181 - val_accuracy: 0.2216\n",
      "Epoch 5/30\n",
      "711/711 [==============================] - 25s 34ms/step - loss: 1.6237 - accuracy: 0.2363 - val_loss: 1.6150 - val_accuracy: 0.2339\n",
      "Epoch 6/30\n",
      "711/711 [==============================] - 25s 35ms/step - loss: 1.6202 - accuracy: 0.2409 - val_loss: 1.6132 - val_accuracy: 0.2283\n",
      "Epoch 7/30\n",
      "711/711 [==============================] - 24s 34ms/step - loss: 1.6181 - accuracy: 0.2448 - val_loss: 1.6240 - val_accuracy: 0.2331\n",
      "Epoch 8/30\n",
      "711/711 [==============================] - 24s 34ms/step - loss: 1.6161 - accuracy: 0.2468 - val_loss: 1.6124 - val_accuracy: 0.2485\n",
      "Epoch 9/30\n",
      "711/711 [==============================] - 25s 35ms/step - loss: 1.6149 - accuracy: 0.2437 - val_loss: 1.6166 - val_accuracy: 0.2335\n",
      "Epoch 10/30\n",
      "711/711 [==============================] - 25s 35ms/step - loss: 1.6158 - accuracy: 0.2446 - val_loss: 1.6231 - val_accuracy: 0.2457\n",
      "Epoch 11/30\n",
      "711/711 [==============================] - 25s 35ms/step - loss: 1.6149 - accuracy: 0.2459 - val_loss: 1.6123 - val_accuracy: 0.2327\n",
      "Epoch 12/30\n",
      "711/711 [==============================] - 25s 35ms/step - loss: 1.6132 - accuracy: 0.2499 - val_loss: 1.6118 - val_accuracy: 0.2537\n",
      "Epoch 13/30\n",
      "711/711 [==============================] - 25s 35ms/step - loss: 1.6123 - accuracy: 0.2492 - val_loss: 1.6116 - val_accuracy: 0.2517\n",
      "Epoch 14/30\n",
      "711/711 [==============================] - 25s 35ms/step - loss: 1.6131 - accuracy: 0.2437 - val_loss: 1.6089 - val_accuracy: 0.2521\n",
      "Epoch 15/30\n",
      "711/711 [==============================] - 25s 35ms/step - loss: 1.6131 - accuracy: 0.2436 - val_loss: 1.6110 - val_accuracy: 0.2568\n",
      "Epoch 16/30\n",
      "711/711 [==============================] - 25s 35ms/step - loss: 1.6136 - accuracy: 0.2445 - val_loss: 1.6128 - val_accuracy: 0.2521\n",
      "Epoch 17/30\n",
      "711/711 [==============================] - 24s 34ms/step - loss: 1.6128 - accuracy: 0.2455 - val_loss: 1.6084 - val_accuracy: 0.2521\n",
      "Epoch 18/30\n",
      "711/711 [==============================] - 25s 35ms/step - loss: 1.6119 - accuracy: 0.2505 - val_loss: 1.6111 - val_accuracy: 0.2509\n",
      "Epoch 19/30\n",
      "711/711 [==============================] - 25s 35ms/step - loss: 1.6123 - accuracy: 0.2458 - val_loss: 1.6103 - val_accuracy: 0.2450\n",
      "Epoch 20/30\n",
      "711/711 [==============================] - 25s 35ms/step - loss: 1.6119 - accuracy: 0.2494 - val_loss: 1.6118 - val_accuracy: 0.2521\n",
      "*******************************************************************\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 7 ...\n",
      "Epoch 1/30\n",
      "711/711 [==============================] - 41s 39ms/step - loss: 2.2548 - accuracy: 0.1928 - val_loss: 1.6588 - val_accuracy: 0.1963\n",
      "Epoch 2/30\n",
      "711/711 [==============================] - 25s 35ms/step - loss: 1.7563 - accuracy: 0.2162 - val_loss: 1.6409 - val_accuracy: 0.2394\n",
      "Epoch 3/30\n",
      "711/711 [==============================] - 25s 35ms/step - loss: 1.6694 - accuracy: 0.2182 - val_loss: 1.6147 - val_accuracy: 0.2505\n",
      "Epoch 4/30\n",
      "711/711 [==============================] - 25s 35ms/step - loss: 1.6369 - accuracy: 0.2329 - val_loss: 1.6136 - val_accuracy: 0.2485\n",
      "Epoch 5/30\n",
      "711/711 [==============================] - 25s 35ms/step - loss: 1.6262 - accuracy: 0.2361 - val_loss: 1.6275 - val_accuracy: 0.2264\n",
      "Epoch 6/30\n",
      "711/711 [==============================] - 25s 35ms/step - loss: 1.6201 - accuracy: 0.2443 - val_loss: 1.6189 - val_accuracy: 0.2446\n",
      "Epoch 7/30\n",
      "711/711 [==============================] - 25s 35ms/step - loss: 1.6178 - accuracy: 0.2429 - val_loss: 1.6168 - val_accuracy: 0.2525\n",
      "*******************************************************************\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 8 ...\n",
      "Epoch 1/30\n",
      "711/711 [==============================] - 39s 36ms/step - loss: 2.2220 - accuracy: 0.1931 - val_loss: 1.6758 - val_accuracy: 0.2521\n",
      "Epoch 2/30\n",
      "711/711 [==============================] - 25s 36ms/step - loss: 1.7394 - accuracy: 0.2173 - val_loss: 1.6207 - val_accuracy: 0.2343\n",
      "Epoch 3/30\n",
      "711/711 [==============================] - 25s 35ms/step - loss: 1.6655 - accuracy: 0.2239 - val_loss: 1.6166 - val_accuracy: 0.2501\n",
      "Epoch 4/30\n",
      "711/711 [==============================] - 25s 35ms/step - loss: 1.6380 - accuracy: 0.2360 - val_loss: 1.6222 - val_accuracy: 0.2513\n",
      "Epoch 5/30\n",
      "711/711 [==============================] - 25s 35ms/step - loss: 1.6257 - accuracy: 0.2378 - val_loss: 1.6186 - val_accuracy: 0.2418\n",
      "Epoch 6/30\n",
      "711/711 [==============================] - 25s 35ms/step - loss: 1.6212 - accuracy: 0.2424 - val_loss: 1.6126 - val_accuracy: 0.2430\n",
      "Epoch 7/30\n",
      "711/711 [==============================] - 25s 35ms/step - loss: 1.6184 - accuracy: 0.2418 - val_loss: 1.6276 - val_accuracy: 0.2275\n",
      "Epoch 8/30\n",
      "711/711 [==============================] - 25s 35ms/step - loss: 1.6173 - accuracy: 0.2443 - val_loss: 1.6127 - val_accuracy: 0.2517\n",
      "Epoch 9/30\n",
      "711/711 [==============================] - 25s 35ms/step - loss: 1.6165 - accuracy: 0.2420 - val_loss: 1.6143 - val_accuracy: 0.2473\n",
      "*******************************************************************\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 9 ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "711/711 [==============================] - 38s 39ms/step - loss: 2.2827 - accuracy: 0.1909 - val_loss: 1.6642 - val_accuracy: 0.2430\n",
      "Epoch 2/30\n",
      "711/711 [==============================] - 25s 35ms/step - loss: 1.7851 - accuracy: 0.2144 - val_loss: 1.6285 - val_accuracy: 0.2335\n",
      "Epoch 3/30\n",
      "711/711 [==============================] - 25s 35ms/step - loss: 1.6803 - accuracy: 0.2229 - val_loss: 1.6180 - val_accuracy: 0.2426\n",
      "Epoch 4/30\n",
      "711/711 [==============================] - 25s 35ms/step - loss: 1.6427 - accuracy: 0.2320 - val_loss: 1.6117 - val_accuracy: 0.2394\n",
      "Epoch 5/30\n",
      "711/711 [==============================] - 25s 35ms/step - loss: 1.6286 - accuracy: 0.2385 - val_loss: 1.7720 - val_accuracy: 0.2327\n",
      "Epoch 6/30\n",
      "711/711 [==============================] - 25s 35ms/step - loss: 1.6201 - accuracy: 0.2422 - val_loss: 1.6111 - val_accuracy: 0.2525\n",
      "Epoch 7/30\n",
      "711/711 [==============================] - 25s 35ms/step - loss: 1.6188 - accuracy: 0.2471 - val_loss: 1.6139 - val_accuracy: 0.2438\n",
      "Epoch 8/30\n",
      "711/711 [==============================] - 25s 35ms/step - loss: 1.6159 - accuracy: 0.2504 - val_loss: 1.6119 - val_accuracy: 0.2327\n",
      "Epoch 9/30\n",
      "711/711 [==============================] - 26s 36ms/step - loss: 1.6161 - accuracy: 0.2433 - val_loss: 1.6117 - val_accuracy: 0.2517\n",
      "*******************************************************************\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 10 ...\n",
      "Epoch 1/30\n",
      "711/711 [==============================] - 41s 39ms/step - loss: 2.2410 - accuracy: 0.1929 - val_loss: 1.6440 - val_accuracy: 0.2252\n",
      "Epoch 2/30\n",
      "711/711 [==============================] - 25s 36ms/step - loss: 1.7518 - accuracy: 0.2208 - val_loss: 1.6249 - val_accuracy: 0.2268\n",
      "Epoch 3/30\n",
      "711/711 [==============================] - 25s 35ms/step - loss: 1.6637 - accuracy: 0.2287 - val_loss: 1.6237 - val_accuracy: 0.2541\n",
      "Epoch 4/30\n",
      "711/711 [==============================] - 25s 35ms/step - loss: 1.6400 - accuracy: 0.2286 - val_loss: 1.6191 - val_accuracy: 0.2541\n",
      "Epoch 5/30\n",
      "711/711 [==============================] - 25s 35ms/step - loss: 1.6268 - accuracy: 0.2321 - val_loss: 1.6623 - val_accuracy: 0.2501\n",
      "Epoch 6/30\n",
      "711/711 [==============================] - 25s 35ms/step - loss: 1.6202 - accuracy: 0.2440 - val_loss: 1.6565 - val_accuracy: 0.2434\n",
      "Epoch 7/30\n",
      "711/711 [==============================] - 25s 35ms/step - loss: 1.6199 - accuracy: 0.2451 - val_loss: 1.6117 - val_accuracy: 0.2497\n",
      "Epoch 8/30\n",
      "711/711 [==============================] - 25s 35ms/step - loss: 1.6163 - accuracy: 0.2409 - val_loss: 1.6102 - val_accuracy: 0.2493\n",
      "Epoch 9/30\n",
      "711/711 [==============================] - 25s 35ms/step - loss: 1.6143 - accuracy: 0.2461 - val_loss: 1.6156 - val_accuracy: 0.2505\n",
      "Epoch 10/30\n",
      "711/711 [==============================] - 25s 35ms/step - loss: 1.6141 - accuracy: 0.2462 - val_loss: 1.6142 - val_accuracy: 0.2366\n",
      "Epoch 11/30\n",
      "711/711 [==============================] - 25s 35ms/step - loss: 1.6140 - accuracy: 0.2466 - val_loss: 1.6108 - val_accuracy: 0.2359\n",
      "*******************************************************************\n"
     ]
    }
   ],
   "source": [
    "split = StratifiedKFold(n_splits = 10, shuffle = True, random_state = 42)\n",
    "\n",
    "# pred = []\n",
    "# pred_ = []\n",
    "\n",
    "fold_no = 1\n",
    "for e , (train_idx, val_idx) in enumerate(split.split(train_x, train_y)):\n",
    "    \n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'Training for fold {fold_no} ...')\n",
    "    \n",
    "    \n",
    "    checkpoint = ModelCheckpoint('./s_model'+f'/check{e}.h5',save_best_only=True)\n",
    "    early_stopping_callback = EarlyStopping(monitor='val_loss', patience=3)\n",
    "    \n",
    "    x_train, y_train = train_x[train_idx], train_y[train_idx]\n",
    "    x_val, y_val = train_x[val_idx], train_y[val_idx]\n",
    "\n",
    "    with strategy.scope():\n",
    "        model = build_fn()\n",
    "        model.compile(optimizer = keras.optimizers.Adam(0.0005),\n",
    "                     loss = keras.losses.SparseCategoricalCrossentropy(),\n",
    "                     metrics=['accuracy'])\n",
    "\n",
    "    history = model.fit(x = x_train, y = y_train, validation_data = (x_val, y_val), \n",
    "                        callbacks=[early_stopping_callback, checkpoint], epochs = 30)\n",
    "    \n",
    "\n",
    "    \n",
    "    print(\"*******************************************************************\")\n",
    "    \n",
    "    fold_no += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_x= np.load('./train_m.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split = StratifiedKFold(n_splits = 10, shuffle = True, random_state = 10)\n",
    "\n",
    "# # pred = []\n",
    "# # pred_ = []\n",
    "\n",
    "# fold_no = 1\n",
    "# for e , (train_idx, val_idx) in enumerate(split.split(train_x, train_y)):\n",
    "    \n",
    "#     print('------------------------------------------------------------------------')\n",
    "#     print(f'Training for fold {fold_no} ...')\n",
    "    \n",
    "    \n",
    "#     checkpoint = ModelCheckpoint('./m_model'+f'/check{e}.h5',save_best_only=True)\n",
    "#     early_stopping_callback = EarlyStopping(monitor='val_loss', patience=5)\n",
    "    \n",
    "#     x_train, y_train = train_x[train_idx], train_y[train_idx]\n",
    "#     x_val, y_val = train_x[val_idx], train_y[val_idx]\n",
    "\n",
    "#     with strategy.scope():\n",
    "#         model = build_fn()\n",
    "#         model.compile(optimizer = keras.optimizers.Adam(0.0001),\n",
    "#                      loss = keras.losses.SparseCategoricalCrossentropy(),\n",
    "#                      metrics=['accuracy'])\n",
    "\n",
    "#     history = model.fit(x = x_train, y = y_train, validation_data = (x_val, y_val), \n",
    "#                         callbacks=[early_stopping_callback, checkpoint], epochs = 30)\n",
    "    \n",
    "\n",
    "    \n",
    "#     print(\"*******************************************************************\")\n",
    "    \n",
    "#     fold_no += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x= np.load('./test_s.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************************************************************\n",
      "*******************************************************************\n",
      "0\n",
      "*******************************************************************\n",
      "*******************************************************************\n",
      "1\n",
      "*******************************************************************\n",
      "*******************************************************************\n",
      "2\n",
      "*******************************************************************\n",
      "*******************************************************************\n",
      "3\n",
      "*******************************************************************\n",
      "*******************************************************************\n",
      "4\n",
      "*******************************************************************\n",
      "*******************************************************************\n",
      "5\n",
      "*******************************************************************\n",
      "*******************************************************************\n",
      "6\n",
      "*******************************************************************\n",
      "*******************************************************************\n",
      "7\n",
      "*******************************************************************\n",
      "*******************************************************************\n",
      "8\n",
      "*******************************************************************\n",
      "*******************************************************************\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "pred1 = []\n",
    "pred1_ = []\n",
    "\n",
    "for e in range(10):\n",
    "    model = build_fn()\n",
    "    model.load_weights('./s_model'+f'/check{e}.h5')\n",
    "    print(\"*******************************************************************\")\n",
    "    pred1.append(model.predict(test_x))\n",
    "    pred1_.append(np.argmax(model.predict(test_x), axis = 1))\n",
    "    print(\"*******************************************************************\")\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_x= np.load('./test_m.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred2 = []\n",
    "# pred2_ = []\n",
    "\n",
    "# for e in range(10):\n",
    "#     model = build_fn()\n",
    "#     model.load_weights('./m_model'+f'/check{e}.h5')\n",
    "#     print(\"*******************************************************************\")\n",
    "#     pred2.append(model.predict(test_x))\n",
    "#     pred2_.append(np.argmax(model.predict(test_x), axis = 1))\n",
    "#     print(\"*******************************************************************\")\n",
    "#     print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_1 = np.argmax(np.sum(pred1, axis =0), axis = 1)\n",
    "# pred_2 = np.argmax(np.sum(pred2, axis =0), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv(\"open/sample_submission.csv\")\n",
    "sample_submission[\"age_\"] = pred_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.to_csv(\"./baseline_10_9.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
